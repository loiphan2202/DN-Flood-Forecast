import json
import os

import numpy as np
import pandas as pd

try:
    from keras.models import load_model
except ImportError:
    from keras.models import load_model
import time
from datetime import datetime, timedelta

import firebase_admin
import plotly.graph_objects as go
import requests
import streamlit as st
import streamlit_card
import tensorflow as tf
from filterpy.kalman import KalmanFilter
from firebase_admin import credentials, db
from PIL import Image
from plotly.subplots import make_subplots
from sklearn.preprocessing import MinMaxScaler
from streamlit_lottie import st_lottie
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText

# Kh·ªüi t·∫°o Firebase
if not firebase_admin._apps:  # Ki·ªÉm tra xem ƒë√£ c√≥ app n√†o ƒë∆∞·ª£c kh·ªüi t·∫°o ch∆∞a
    # ƒê·ªçc c·∫•u h√¨nh Firebase t·ª´ file JSON
    config_path = os.path.join(os.path.dirname(__file__), './firebase_config.json')
    with open(config_path) as f:
        firebase_config = json.load(f)

    cred = credentials.Certificate("./firebase_credentials.json")
    firebase_admin.initialize_app(cred, {
        'databaseURL': firebase_config['databaseURL']
    })

# ƒê·∫£m b·∫£o folder model t·ªìn t·∫°i tr∆∞·ªõc khi load
model_path = './best_model'

if os.path.exists(model_path):
    try:
        # Load model t·ª´ folder l∆∞u tr∆∞c ƒë√≥
        model = load_model(model_path)
        st.success("Model ƒë√£ ƒë∆∞·ª£c load th√†nh c√¥ng.")
        print("C·∫•u tr√∫c model:")
        model.summary()
    except Exception as e:
        st.error(f"L·ªói khi load model: {str(e)}")
        model = None
else:
    st.error(f"Kh√¥ng t√¨m th·∫•y folder model t·∫°i {model_path}")
    model = None

# Kh·ªüi t·∫°o scaler (gi·∫£ ƒë·ªãnh d·ªØ li·ªáu c·∫ßn chu·∫©n h√≥a t·ª´ 0-1)
# scaler = MinMaxScaler()

class SensorKalmanFilter:
    def __init__(self, initial_value, process_variance, measurement_variance):
        self.kf = KalmanFilter(dim_x=1, dim_z=1)
        self.kf.x = np.array([[initial_value]])  # Tr·∫°ng th√°i ban ƒë·∫ßu
        self.kf.P *= process_variance  # ƒê·ªô kh√¥ng ch·∫Øc ch·∫Øn ban ƒë·∫ßu
        self.kf.R = measurement_variance  # Nhi·ªÖu ƒëo
        self.kf.Q = process_variance  # Nhi·ªÖu qu√° tr√¨nh
        
        # Ma tr·∫≠n chuy·ªÉn tr·∫°ng th√°i
        self.kf.F = np.array([[1.]])
        # Ma tr·∫≠n ƒëo
        self.kf.H = np.array([[1.]])

    def update(self, measurement):
        self.kf.predict()
        self.kf.update(measurement)
        return self.kf.x[0, 0]

def apply_kalman_filter(data_series):
    """√Åp d·ª•ng b·ªô l·ªçc Kalman cho m·ªôt chu·ªói d·ªØ li·ªáu"""
    # Kh·ªüi t·∫°o v·ªõi gi√° tr·ªã ƒë·∫ßu ti√™n
    initial_value = data_series.iloc[0]
    
    # T√≠nh to√°n ph∆∞∆°ng sai cho vi·ªác tinh ch·ªânh b·ªô l·ªçc
    measurement_variance = np.var(data_series) if len(data_series) > 1 else 1.0
    process_variance = measurement_variance * 0.1  # Th∆∞·ªùng nh·ªè h∆°n measurement_variance
    
    # Kh·ªüi t·∫°o b·ªô l·ªçc
    kf = SensorKalmanFilter(initial_value, process_variance, measurement_variance)
    
    # √Åp d·ª•ng b·ªô l·ªçc
    filtered_data = []
    for value in data_series:
        filtered_value = kf.update(value)
        filtered_data.append(filtered_value)
    
    return pd.Series(filtered_data, index=data_series.index)

def clean_and_filter_data(df):
    """L√†m s·∫°ch v√† l·ªçc d·ªØ li·ªáu s·ª≠ d·ª•ng Kalman Filter"""
    # T·∫°o b·∫£n sao ƒë·ªÉ kh√¥ng ·∫£nh h∆∞·ªüng ƒë·∫øn d·ªØ li·ªáu g·ªëc
    df_cleaned = df.copy()
    
    # X·ª≠ l√Ω missing values
    df_cleaned = df_cleaned.dropna()
    
    # √Åp d·ª•ng Kalman Filter cho t·ª´ng c·∫£m bi·∫øn
    for column in df_cleaned.columns:
        df_cleaned[column] = apply_kalman_filter(df_cleaned[column])
    
    # Ki·ªÉm tra gi√° tr·ªã h·ª£p l·ªá cho t·ª´ng c·∫£m bi·∫øn
    valid_ranges = {
        'Distance': (0, 5),           # Kho·∫£ng c√°ch t·ª´ 0-5m
        'Flow Rate': (0, 10),         # L∆∞u l∆∞·ª£ng t·ª´ 0-10 L/min
        'humidity': (0, 100),         # ƒê·ªô ·∫©m kh√¥ng kh√≠ 0-100%
        'rain': (0, 100),             # L∆∞·ª£ng m∆∞a 0-100mm
        'soil_moisture': (0, 100),    # ƒê·ªô ·∫©m ƒë·∫•t 0-100%
        'temperature': (0, 50)        # Nhi·ªát ƒë·ªô 0-50¬∞C
    }
    
    for column, (min_val, max_val) in valid_ranges.items():
        df_cleaned = df_cleaned[(df_cleaned[column] >= min_val) & 
                              (df_cleaned[column] <= max_val)]
    
    # S·∫Øp x·∫øp theo th·ªùi gian
    df_cleaned = df_cleaned.sort_index()
    
    return df_cleaned

def send_email(subject, body):
    """G·ª≠i email v·ªõi ti√™u ƒë·ªÅ v√† n·ªôi dung"""
    try:
        # C·∫•u h√¨nh email
        sender_email = "minnguyt277@gmail.com"
        receiver_email = "loiphan2102004ptl@gmail.com"
        password = "nqqh vyqb arit whsq"

        # T·∫°o email
        msg = MIMEMultipart()
        msg['From'] = sender_email
        msg['To'] = receiver_email
        msg['Subject'] = subject
        msg.attach(MIMEText(body, 'plain'))

        # G·ª≠i email
        server = smtplib.SMTP('smtp.gmail.com', 587)
        server.starttls()
        server.login(sender_email, password)
        text = msg.as_string()
        server.sendmail(sender_email, receiver_email, text)
        server.quit()
        print("Email ƒë√£ ƒë∆∞·ª£c g·ª≠i th√†nh c√¥ng.")
    except Exception as e:
        print(f"L·ªói khi g·ª≠i email: {str(e)}")

def check_and_send_alert(df):
    """Ki·ªÉm tra v√† g·ª≠i c·∫£nh b√°o n·∫øu m·ª±c n∆∞·ªõc ƒë·∫°t ng∆∞·ª°ng"""
    if not df.empty:
        latest_data = df.iloc[-1]
        if latest_data['Distance'] >= 2.7:
            subject = "C·∫£nh b√°o: M·ª±c n∆∞·ªõc ƒë·∫°t ng∆∞·ª°ng 2.7m"
            body = f"D·ªØ li·ªáu m·ªõi nh·∫•t:\n\n{df.to_string()}"
            send_email(subject, body)

def get_realtime_data():
    """L·∫•y v√† k·∫øt h·ª£p d·ªØ li·ªáu t·ª´ c·∫£ hai ESP32"""
    try:
        # L·∫•y reference ƒë·∫øn c√°c node ESP32
        esp32_1_ref = db.reference('devices/ESP32_1/sensor_data')
        esp32_2_ref = db.reference('devices/ESP32_2/sensor_data')
        
        # L·∫•y d·ªØ li·ªáu t·ª´ c·∫£ hai ESP32
        data_1 = esp32_1_ref.get()
        data_2 = esp32_2_ref.get()
        
        if data_1 and data_2:
            # T·∫°o DataFrame r·ªóng ƒë·ªÉ l∆∞u d·ªØ li·ªáu k·∫øt h·ª£p
            combined_data = []
            
            # Duy·ªát qua c√°c timestamp
            for timestamp in data_1:
                if timestamp in data_2:
                    # L·∫•y d·ªØ li·ªáu t·ª´ c·∫£ hai thi·∫øt b·ªã
                    sensor_1 = data_1[timestamp]
                    sensor_2 = data_2[timestamp]
                    
                    # K·∫øt h·ª£p d·ªØ li·ªáu
                    combined_row = {
                        'datetime': sensor_1['datetime'],
                        'Distance': float(sensor_2.get('distance', 0)),
                        'Flow Rate': float(sensor_2.get('flow_rate', 0)),
                        'humidity': float(sensor_1.get('humidity', 0)),
                        'rain': float(sensor_1.get('rain', 0)),
                        'soil_moisture': float(sensor_1.get('soil_moisture', 0)),
                        'temperature': float(sensor_1.get('temperature', 0))
                    }
                    combined_data.append(combined_row)
            
            # T·∫°o DataFrame t·ª´ d·ªØ li·ªáu k·∫øt h·ª£p
            df = pd.DataFrame(combined_data)
            
            # Chuy·ªÉn ƒë·ªïi c·ªôt datetime th√†nh index
            df['datetime'] = pd.to_datetime(df['datetime'])
            df.set_index('datetime', inplace=True)
            df.sort_index(inplace=True)
            
            # In ra ƒë·ªÉ debug
            print("DataFrame sau khi x·ª≠ l√Ω:", df)
            
            # √Åp d·ª•ng Kalman Filter v√† l√†m s·∫°ch d·ªØ li·ªáu
            df = clean_and_filter_data(df)
            
            # Ki·ªÉm tra v√† g·ª≠i c·∫£nh b√°o n·∫øu c·∫ßn
            check_and_send_alert(df)
            
            return df
            
        else:
            print("Kh√¥ng c√≥ d·ªØ li·ªáu t·ª´ m·ªôt ho·∫∑c c·∫£ hai ESP32")
            return pd.DataFrame(columns=["Distance", "Flow Rate", "humidity", 
                                      "rain", "soil_moisture", "temperature"])
            
    except Exception as e:
        print(f"L·ªói khi l·∫•y d·ªØ li·ªáu t·ª´ Firebase: {str(e)}")
        return pd.DataFrame(columns=["Distance", "Flow Rate", "humidity", 
                                   "rain", "soil_moisture", "temperature"])

# Th√™m cache cho model v√† scaler
@st.cache_resource
def load_model_and_scaler():
    """Cache model v√† scaler ƒë·ªÉ tr√°nh load l·∫°i nhi·ªÅu l·∫ßn"""
    model_path = './best_model'
    if os.path.exists(model_path):
        try:
            model = load_model(model_path)
            scaler = MinMaxScaler()
            # T·∫°o d·ªØ li·ªáu m·∫´u ƒë·ªÉ fit scaler
            sample_data = np.array([
                [0, 0, 0, 0, 0, 0],  # min values
                [5, 10, 100, 100, 100, 50]  # max values t·ª´ valid_ranges
            ])
            scaler.fit(sample_data)
            return model, scaler
        except Exception as e:
            st.error(f"L·ªói khi load model: {str(e)}")
    return None, None

# S·ª≠a decorator v√† tham s·ªë c·ªßa h√†m prepare_data_for_prediction
@st.cache_data(ttl=60)  # Cache trong 60s
def prepare_data_for_prediction(df, _scaler):  # Th√™m d·∫•u g·∫°ch d∆∞·ªõi tr∆∞·ªõc scaler
    """Chu·∫©n b·ªã d·ªØ li·ªáu cho d·ª± ƒëo√°n v·ªõi t·ªëi ∆∞u h√≥a"""
    if len(df) < 24:
        return None
        
    required_columns = ["Distance", "Flow Rate", "humidity", "rain", "soil_moisture", "temperature"]
    df = df[required_columns].copy()
    
    # S·ª≠ d·ª•ng scaler ƒë√£ ƒë∆∞·ª£c fit t·ª´ tham s·ªë
    scaled_data = _scaler.transform(df.values)  # D√πng transform thay v√¨ fit_transform
    
    # Optimize feature expansion
    if len(scaled_data) > 24:
        scaled_data = scaled_data[-24:]
    elif len(scaled_data) < 24:
        padding = np.zeros((24 - len(scaled_data), scaled_data.shape[1]))
        scaled_data = np.vstack([padding, scaled_data])
    
    # Vectorized feature expansion
    expanded_data = np.zeros((24, 18))
    expanded_data[:, :6] = scaled_data
    
    # Vectorized calculations for additional features
    for i in range(6):
        expanded_data[:, 6+i] = np.convolve(scaled_data[:, i], np.ones(3)/3, mode='same')
        expanded_data[:, 12+i] = np.gradient(scaled_data[:, i])
    
    return expanded_data.reshape((1, 24, 18))

# T∆∞∆°ng t·ª± cho h√†m make_prediction
@st.cache_data(ttl=60)
def make_prediction(_model, scaled_data):  # Th√™m d·∫•u g·∫°ch d∆∞·ªõi
    """Th·ª±c hi·ªán d·ª± ƒëo√°n v·ªõi t·ªëi ∆∞u h√≥a"""
    if _model is None:
        return None, None
        
    try:
        # Batch prediction ƒë·ªÉ tƒÉng t·ªëc
        with tf.device('/CPU:0'):  # Force CPU usage for small batches
            prediction = _model.predict(scaled_data, batch_size=1, verbose=0)
        
        # T·ªëi ∆∞u vi·ªác t·∫°o timestamps
        current_time = pd.Timestamp.now()
        future_times = pd.date_range(start=current_time, periods=3, freq='D')
        
        prediction = prediction[0, :3, :]
        
        return prediction, future_times
    except Exception as e:
        st.error(f"L·ªói khi d·ª± ƒëo√°n: {str(e)}")
        return None, None

def display_realtime_data(df):
    """Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì realtime v·ªõi style ƒë·∫πp h∆°n"""
    fig = make_subplots(
        rows=6, cols=1,
        subplot_titles=(
            'Kho·∫£ng c√°ch (m)',
            'L∆∞u l∆∞·ª£ng (L/min)',
            'ƒê·ªô ·∫©m kh√¥ng kh√≠ (%)',
            'L∆∞·ª£ng m∆∞a (mm)',
            'ƒê·ªô ·∫©m ƒë·∫•t (%)',
            'Nhi·ªát ƒë·ªô (¬∞C)'
        ),
        vertical_spacing=0.11
    )

    colors = {
        "Distance": "#1f77b4",      # Xanh d∆∞∆°ng
        "Flow Rate": "#ff7f0e",     # Cam
        "humidity": "#2ca02c",      # Xanh l√°
        "rain": "#d62728",          # ƒê·ªè
        "soil_moisture": "#9467bd",  # T√≠m
        "temperature": "#8c564b"     # N√¢u
    }

    metrics = ["Distance", "Flow Rate", "humidity", "rain", "soil_moisture", "temperature"]
    
    for i, metric in enumerate(metrics, start=1):
        fig.add_trace(
            go.Scatter(
                x=df.index,
                y=df[metric],
                name=metric,
                line=dict(
                    color=colors[metric],
                    width=2
                ),
                mode='lines'
            ),
            row=i,
            col=1
        )

        # Th√™m grid lines v√† style cho m·ªói subplot
        fig.update_xaxes(
            showgrid=True,
            gridwidth=1,
            gridcolor='rgba(128, 128, 128, 0.2)',
            row=i,
            col=1,
            tickformat='%H:%M\n%d/%m/%y'
        )
        fig.update_yaxes(
            showgrid=True,
            gridwidth=1,
            gridcolor='rgba(128, 128, 128, 0.2)',
            row=i,
            col=1
        )

    fig.update_layout(
        height=900,
        showlegend=False,
        plot_bgcolor='white',
        paper_bgcolor='white',
        margin=dict(l=50, r=50, t=50, b=50),
        title=dict(
            text="D·ªØ li·ªáu realtime t·ª´ c·∫£m bi·∫øn",
            x=0.5,
            y=0.98,
            xanchor='center',
            yanchor='top',
            font=dict(size=24)
        ),
        font=dict(
            family="Arial, sans-serif",
            size=12
        )
    )

    # Th√™m hover template
    for trace in fig.data:
        trace.update(
            hovertemplate=(
                "<b>Th·ªùi gian:</b> %{x}<br>" +
                "<b>Gi√° tr·ªã:</b> %{y:.2f}<br>" +
                "<extra></extra>"
            )
        )

    return fig

def display_predictions(predictions, future_times, _scaler):  # Th√™m d·∫•u g·∫°ch d∆∞·ªõi
    """Hi·ªÉn th·ªã k·∫øt qu·∫£ d·ª± ƒëo√°n v√† c·∫£nh b√°o"""
    if predictions is None or future_times is None:
        st.error("Kh√¥ng c√≥ d·ªØ li·ªáu d·ª± ƒëo√°n")
        return None
        
    try:
        temp_array = np.zeros((len(predictions), 6))
        temp_array[:, 0] = predictions[:, 0]
        temp_array[:, 3] = predictions[:, 1]
        
        # S·ª≠ d·ª•ng scaler t·ª´ tham s·ªë
        predictions_original = _scaler.inverse_transform(temp_array)
        
        distance_pred = predictions_original[:, 0] + 1
        rain_pred = predictions_original[:, 3] + 10
        
        fig = make_subplots(rows=2, cols=1, 
                           subplot_titles=('D·ª± ƒëo√°n m·ª±c n∆∞·ªõc (m)', 'D·ª± ƒëo√°n l∆∞·ª£ng m∆∞a (mm)'))
        
        # V·∫Ω bi·ªÉu ƒë·ªì cho m·ª±c n∆∞·ªõc
        fig.add_trace(go.Scatter(x=future_times, y=distance_pred, 
                                name='M·ª±c n∆∞·ªõc'), row=1, col=1)
        fig.add_hline(y=3, line_dash="dash", line_color="red", 
                     annotation_text="Ng∆∞·ª°ng nguy hi·ªÉm: 3m", row=1, col=1)
        
        # V·∫Ω bi·ªÉu ƒë·ªì cho l∆∞·ª£ng m∆∞a
        fig.add_trace(go.Scatter(x=future_times, y=rain_pred, 
                                name='L∆∞·ª£ng m∆∞a'), row=2, col=1)
        fig.add_hline(y=90, line_dash="dash", line_color="red", 
                     annotation_text="Ng∆∞·ª°ng nguy hi·ªÉm: 90mm", row=2, col=1)
        
        fig.update_layout(height=600, title='D·ª± b√°o cho 3 ng√†y ti·∫øp theo')
        
        # Hi·ªÉn th·ªã c·∫£nh b√°o
        for i in range(len(future_times)):
            date = future_times[i].strftime('%d/%m/%Y')
            if distance_pred[i] >= 3:
                st.error(f"‚ö†Ô∏è C·∫¢NH B√ÅO: M·ª±c n∆∞·ªõc d·ª± b√°o cho ng√†y {date} l√† {distance_pred[i]:.2f}m - V∆Ø·ª¢T NG∆Ø·ª†NG AN TO√ÄN!")
            if rain_pred[i] >= 90:
                st.error(f"‚ö†Ô∏è C·∫¢NH B√ÅO: L∆∞·ª£ng m∆∞a d·ª± b√°o cho ng√†y {date} l√† {rain_pred[i]:.2f}mm - V∆Ø·ª¢T NG∆Ø·ª†NG AN TO√ÄN!")
        
        return fig
    except Exception as e:
        st.error(f"L·ªói khi hi·ªÉn th·ªã d·ª± ƒëo√°n: {str(e)}")
        return None

# Th√™m h√†m load animation
def load_lottie_url(url):
    """Load animation t·ª´ URL"""
    r = requests.get(url)
    if r.status_code != 200:
        return None
    return r.json()

# C·∫≠p nh·∫≠t CSS v·ªõi th√™m hi·ªáu ·ª©ng v√† m√†u s·∫Øc
def load_css():
    st.markdown("""
        <style>
        /* Main container */
        .main {
            padding: 1rem 2rem;
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
        }
        
        /* Header styling */
        .header-container {
            background: rgba(255, 255, 255, 0.95);
            padding: 1.5rem;
            border-radius: 15px;
            box-shadow: 0 8px 32px 0 rgba(31, 38, 135, 0.15);
            backdrop-filter: blur(4px);
            margin-bottom: 2rem;
            transition: all 0.3s ease;
        }
        
        /* Tabs styling */
        .stTabs [data-baseweb="tab-list"] {
            gap: 4px;
            background: rgba(255, 255, 255, 0.8);
            border-radius: 15px;
            padding: 10px;
            box-shadow: 0 4px 12px rgba(0,0,0,0.1);
        }
        
        .stTabs [data-baseweb="tab"] {
            background: rgba(255, 255, 255, 0.9);
            border-radius: 10px;
            padding: 15px 25px;
            font-weight: 500;
            transition: all 0.2s ease;
        }
        
        .stTabs [aria-selected="true"] {
            background: linear-gradient(135deg, #00acee 0%, #1e90ff 100%);
            color: white;
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0,172,238,0.3);
        }
        
        /* Sensor cards */
        .sensor-card {
            background: white;
            padding: 1.5rem;
            border-radius: 15px;
            box-shadow: 0 8px 32px 0 rgba(31, 38, 135, 0.15);
            margin-bottom: 1.5rem;
            transition: transform 0.3s ease;
            border: 1px solid rgba(255, 255, 255, 0.18);
        }
        
        .sensor-card:hover {
            transform: translateY(-5px);
        }
        
        .sensor-value {
            font-size: 2rem;
            font-weight: bold;
            color: #00acee;
            margin: 0.5rem 0;
        }
        
        /* Charts container */
        .chart-container {
            background: white;
            padding: 1.5rem;
            border-radius: 15px;
            box-shadow: 0 8px 32px 0 rgba(31, 38, 135, 0.15);
            margin: 1.5rem 0;
        }
        
        /* Buttons */
        .stButton button {
            background: linear-gradient(135deg, #00acee 0%, #1e90ff 100%);
            color: white;
            border: none;
            padding: 0.75rem 1.5rem;
            border-radius: 10px;
            font-weight: 500;
            transition: all 0.3s ease;
            box-shadow: 0 4px 12px rgba(0,172,238,0.3);
        }
        
        .stButton button:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 16px rgba(0,172,238,0.4);
        }
        
        /* Loading animation */
        .stSpinner {
            text-align: center;
            padding: 2rem;
        }
        </style>
    """, unsafe_allow_html=True)

def create_metric_card(icon, title, value, unit, trend=None):
    """T·∫°o card hi·ªÉn th·ªã metric v·ªõi animation"""
    trend_html = ""
    if trend is not None:
        color = "#00c853" if trend > 0 else "#ff3d00"
        arrow = "‚Üë" if trend > 0 else "‚Üì"
        trend_html = f'<div style="color: {color}">{arrow} {abs(trend)}%</div>'
    
    return f"""
        <div class="sensor-card">
            <div style="font-size: 1.5rem; color: #666;">{icon} {title}</div>
            <div class="sensor-value">{value} {unit}</div>
            {trend_html}
        </div>
    """

def calculate_trend(current_value, previous_value):
    """T√≠nh to√°n xu h∆∞·ªõng thay ƒë·ªïi"""
    if previous_value is None:
        return None
    return ((current_value - previous_value) / previous_value) * 100

def load_animations():
    """Load t·∫•t c·∫£ animations c·∫ßn thi·∫øt"""
    return {
        'monitoring': load_lottie_url("https://assets5.lottiefiles.com/packages/lf20_qp1q7mct.json"),
        'weather': load_lottie_url("https://assets5.lottiefiles.com/private_files/lf30_jmgekfqg.json"),
        'warning': load_lottie_url("https://assets9.lottiefiles.com/packages/lf20_qmfs6c3i.json")
    }

def main():
    # Load CSS
    load_css()
    
    # Load model v√† scaler m·ªôt l·∫ßn duy nh·∫•t
    model, scaler = load_model_and_scaler()
    
    # Load animations/images
    animations = load_animations()
    
    # Header section v·ªõi animation m∆∞·ª£t m√†
    with st.container():
        col1, col2 = st.columns([2,1])
        with col1:
            st.markdown('<div class="header-container">', unsafe_allow_html=True)
            st.title("üåä H·ªá th·ªëng Gi√°m s√°t v√† D·ª± b√°o L≈© l·ª•t")
            st.markdown("##### Theo d√µi v√† d·ª± b√°o t√¨nh h√¨nh th·ªùi ti·∫øt theo th·ªùi gian th·ª±c")
            st.markdown('</div>', unsafe_allow_html=True)
        with col2:
            st_lottie(animations['weather'], height=180, key="header_animation")

    # Tabs v·ªõi hi·ªáu ·ª©ng
    tab1, tab2 = st.tabs(["üìä Gi√°m s√°t d·ªØ li·ªáu", "üîÆ D·ª± b√°o"])
    
    with tab1:
        st.header("D·ªØ li·ªáu Realtime")
        
        # L·∫•y d·ªØ li·ªáu realtime
        df_realtime = get_realtime_data()
        
        if not df_realtime.empty:
            # Hi·ªÉn th·ªã metric cards
            latest_data = df_realtime.iloc[-1]
            previous_data = df_realtime.iloc[-2] if len(df_realtime) > 1 else None
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                trend = calculate_trend(latest_data['Distance'], previous_data['Distance'] if previous_data is not None else None)
                st.markdown(create_metric_card(
                    "üíß", 
                    "M·ª±c n∆∞·ªõc", 
                    f"{latest_data['Distance']:.1f}", 
                    "m",
                    trend
                ), unsafe_allow_html=True)
            
            with col2:
                trend = calculate_trend(latest_data['rain'], previous_data['rain'] if previous_data is not None else None)
                st.markdown(create_metric_card(
                    "üåßÔ∏è", 
                    "L∆∞·ª£ng m∆∞a", 
                    f"{latest_data['rain']:.0f}", 
                    "mm",
                    trend
                ), unsafe_allow_html=True)
            
            with col3:
                trend = calculate_trend(latest_data['temperature'], previous_data['temperature'] if previous_data is not None else None)
                st.markdown(create_metric_card(
                    "üå°Ô∏è", 
                    "Nhi·ªát ƒë·ªô", 
                    f"{latest_data['temperature']:.1f}", 
                    "¬∞C",
                    trend
                ), unsafe_allow_html=True)
            
            # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì
            st.markdown('<div class="chart-container">', unsafe_allow_html=True)
            fig = display_realtime_data(df_realtime)
            st.plotly_chart(fig, use_container_width=True)
            st.markdown('</div>', unsafe_allow_html=True)
        else:
            st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu realtime")
    
    with tab2:
        st.header("D·ª± b√°o t·ª´ m√¥ h√¨nh")
        
        col1, col2 = st.columns([3,1])
        with col1:
            st.info("ü§ñ Model LSTM ƒë∆∞·ª£c training v·ªõi d·ªØ li·ªáu 6 th√°ng g·∫ßn nh·∫•t")
            predict_container = st.empty()
        with col2:
            st_lottie(animations['monitoring'], height=200, key="predict_animation")
            predict_button = st.button("üîÑ C·∫≠p nh·∫≠t d·ª± b√°o", key="predict")
            
        if predict_button:
            with st.spinner('ƒêang th·ª±c hi·ªán d·ª± ƒëo√°n...'):
                if not df_realtime.empty and model is not None and scaler is not None:
                    scaled_data = prepare_data_for_prediction(df_realtime, scaler)
                    if scaled_data is not None:
                        predictions, future_times = make_prediction(model, scaled_data)
                        if predictions is not None:
                            # Truy·ªÅn scaler v√†o h√†m display_predictions
                            fig_predictions = display_predictions(predictions, future_times, scaler)
                            if fig_predictions is not None:
                                predict_container.plotly_chart(fig_predictions, use_container_width=True)
                            else:
                                predict_container.error("L·ªói khi t·∫°o bi·ªÉu ƒë·ªì d·ª± ƒëo√°n")
                        else:
                            predict_container.warning("Kh√¥ng th·ªÉ th·ª±c hi·ªán d·ª± ƒëo√°n")
                    else:
                        predict_container.warning("Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ d·ª± ƒëo√°n")
                else:
                    predict_container.warning("Thi·∫øu d·ªØ li·ªáu ho·∫∑c model ch∆∞a ƒë∆∞·ª£c load")

    # Footer v·ªõi th√¥ng tin c·∫≠p nh·∫≠t
    st.markdown("---")
    st.markdown(f"üïí C·∫≠p nh·∫≠t l·∫ßn cu·ªëi: **{datetime.now().strftime('%H:%M:%S %d/%m/%Y')}**")

if __name__ == "__main__":
    main()
